{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and settings\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# mdanalysis\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis.align import alignto\n",
    "from MDAnalysis.analysis.pca import PCA\n",
    "# biopython\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB.DSSP import DSSP           # for secondary structure selection\n",
    "from Bio.PDB.SASA import ShrakeRupley   # for SASA calculation\n",
    "# for visualisation\n",
    "import nglview as nv\n",
    "from IPython.display import display\n",
    "# for multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "# surpress warnings\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    module=r'.*randpool'\n",
    ")\n",
    "\n",
    "# pandas settings\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# base directories\n",
    "base_directory = \"/biggin/b212/bioc1781/Projects/CTNS/human/monomer/red-msa/content/\"\n",
    "structure_directory = base_directory + \"Structures/\" # directory with the AF2 ensemble, cannot be the same as base directory\n",
    "\n",
    "# reference structures\n",
    "outward_open_pdb = base_directory + \"8DKE_cytosol_noNTD.pdb\"\n",
    "inward_open_pdb  = base_directory + \"8DKI_lumen_noNTD.pdb\"\n",
    "\n",
    "# settings\n",
    "selection_for_writeout = \"protein and not (resid 358-367) and not (resid 260 and (not backbone))\" # useful if you want all the outputs to have a specific selection\n",
    "resid_offset    = 115           # first resID in the reference structures if the chain does not start from 1\n",
    "# structure filtering\n",
    "thresh_rmsd     = 6             # threshold for discarding structures based on RMSD\n",
    "thresh_pLDDT    = 80            # threshold for discarding structures based on pLDDT\n",
    "diffmat_thresh  = 0             # threshold for ignoring atoms in RMSD calculations based on how much they differ between the reference structures\n",
    "# analysis\n",
    "num_processes   = 16            # CPU cores to use for multiprocessing\n",
    "n_pcs           = 3             # number of principal components to keep in PCA\n",
    "# monte carlo\n",
    "mc_temp         = 500           # monte carlo temperature\n",
    "mc_wf_sasa      = 0             # monte carlo energy function weight factor for SASA\n",
    "mc_n_runs       = 10000         # number of monte carlo runs\n",
    "mc_n_bins       = 6             # so mc_n_bins is the total number of bins (because of reference structures and zero indexing)\n",
    "collective_variable = 'PC1'     # collective_variable to bin for path finding\n",
    "# for plotting\n",
    "plot_variable_1     = 'PC1'   \n",
    "plot_variable_2     = 'PC3'\n",
    "plot_variable_3     = 'sasa'\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "# universes for reference structures\n",
    "u_outward_open = mda.Universe(outward_open_pdb, outward_open_pdb)\n",
    "u_inward_open  = mda.Universe(inward_open_pdb, inward_open_pdb)\n",
    "\n",
    "# align reference structures to eachother\n",
    "alignto(u_inward_open, u_outward_open, select=rmsd_selection, weights=\"mass\")\n",
    "\n",
    "# write reindexed pdbs of reference structures for inclusion in the ensemble\n",
    "u_outward_open.atoms.residues.resids -= resid_offset\n",
    "u_outward_open.atoms.write(structure_directory + \"ref_outward.pdb\")\n",
    "u_outward_open.atoms.residues.resids += resid_offset\n",
    "#\n",
    "u_inward_open.atoms.residues.resids -= resid_offset\n",
    "u_inward_open.atoms.write(structure_directory + \"ref_inward.pdb\")\n",
    "u_inward_open.atoms.residues.resids += resid_offset\n",
    "\n",
    "# get list of all files in structure directory directory with the pdb extension\n",
    "structures = [f for f in os.listdir(structure_directory) if f.endswith('.pdb')]\n",
    "structures.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatic \"clever\" selection definer\n",
    "\n",
    "# conserved residues\n",
    "conserved_residues = []\n",
    "\n",
    "# temporary universe\n",
    "u = u_outward_open\n",
    "\n",
    "# identify regions of secondary structure\n",
    "p = PDBParser()\n",
    "structure = p.get_structure('reference', outward_open_pdb)\n",
    "model = structure[0]\n",
    "dssp = DSSP(model, outward_open_pdb, dssp='mkdssp')\n",
    "\n",
    "helices = []\n",
    "sheets  = []\n",
    "loops   = []\n",
    "\n",
    "# get secondary structure labels for resIDs\n",
    "for key in dssp.keys():\n",
    "    if dssp[key][2] == 'H' or dssp[key][2] == 'G' or dssp[key][2] == 'I':\n",
    "        helices.append(key[1][1])\n",
    "    elif dssp[key][2] == 'E':\n",
    "        sheets.append(key[1][1])\n",
    "    elif dssp[key][2] == 'T' or dssp[key][2] == 'S':\n",
    "        loops.append(key[1][1])\n",
    "    \n",
    "helices = sorted(list(set(helices)))\n",
    "sheets = sorted(list(set(sheets)))\n",
    "loops = sorted(list(set(loops)))\n",
    "\n",
    "helices_contiguous = []\n",
    "sheets_contiguous  = []\n",
    "loops_contiguous   = []\n",
    "\n",
    "# get contiguous regions of secondary structure\n",
    "for i in range(len(helices)):\n",
    "    if i == 0:\n",
    "        helices_contiguous.append([helices[i]])\n",
    "    elif helices[i] == helices[i-1] + 1:\n",
    "        helices_contiguous[-1].append(helices[i])\n",
    "    else:\n",
    "        helices_contiguous.append([helices[i]])\n",
    "\n",
    "for i in range(len(sheets)):\n",
    "    if i == 0:\n",
    "        sheets_contiguous.append([sheets[i]])\n",
    "    elif sheets[i] == sheets[i-1] + 1:\n",
    "        sheets_contiguous[-1].append(sheets[i])\n",
    "    else:\n",
    "        sheets_contiguous.append([sheets[i]])\n",
    "\n",
    "for i in range(len(loops)):\n",
    "    if i == 0:\n",
    "        loops_contiguous.append([loops[i]])\n",
    "    elif loops[i] == loops[i-1] + 1:\n",
    "        loops_contiguous[-1].append(loops[i])\n",
    "    else:\n",
    "        loops_contiguous.append([loops[i]])\n",
    "\n",
    "selection_helices = []\n",
    "selection_sheets  = []\n",
    "selection_loops   = []\n",
    "\n",
    "# make mdanalysis selections corresponding to these regions\n",
    "for i in range(len(helices_contiguous)):\n",
    "    selection_helices.append('(resid %s-%s and (name CA))' % (helices_contiguous[i][0], helices_contiguous[i][-1]))\n",
    "for i in range(len(sheets_contiguous)):\n",
    "    selection_sheets.append('(resid %s-%s and (name CA))' % (sheets_contiguous[i][0], sheets_contiguous[i][-1]))\n",
    "for i in range(len(loops_contiguous)):\n",
    "    selection_loops.append('(resid %s-%s and (name CA))' % (loops_contiguous[i][0], loops_contiguous[i][-1]))\n",
    "\n",
    "# format selections\n",
    "selection_helices = ','.join(selection_helices)\n",
    "selection_helices = selection_helices.replace(',', ' or ')\n",
    "selection_sheets = ','.join(selection_sheets)\n",
    "selection_sheets = selection_sheets.replace(',', ' or ')\n",
    "selection_loops = ','.join(selection_loops)\n",
    "selection_loops = selection_loops.replace(',', ' or ')\n",
    "\n",
    "endstates = {}\n",
    "\n",
    "# trying to be clever and getting rmsd_selection for which to compare rmsd by comparing the distance matrices of the two end states\n",
    "for end_state in [u_outward_open, u_inward_open]:\n",
    "    u = end_state.select_atoms('name CA')\n",
    "    distance_matrix = []\n",
    "    for i in u.atoms:\n",
    "        for j in u.atoms:\n",
    "                distance_matrix.append(np.linalg.norm(i.position - j.position)) # append distance between atoms to distance array\n",
    "    \n",
    "    # reshape to a square matrix and append to dictionary\n",
    "    distance_matrix = np.array(distance_matrix).reshape((len(u.atoms),len(u.atoms)))\n",
    "    endstates[end_state] = distance_matrix\n",
    "\n",
    "# subtract the distance matrices to get the difference matrix\n",
    "ca_dist_difference_matrix = endstates[u_outward_open] - endstates[u_inward_open]\n",
    "\n",
    "resids_from_ca_dist_diffmat = []\n",
    "\n",
    "# get the resid of the residues that differ by more than the threshold in absolute terms\n",
    "above_thresh = np.where(abs(ca_dist_difference_matrix) >= diffmat_thresh)\n",
    "for i in range(len(above_thresh[0])):\n",
    "    resids_from_ca_dist_diffmat.append(u.atoms[above_thresh[0][i]].resid)\n",
    "resids_from_ca_dist_diffmat = list(set(resids_from_ca_dist_diffmat))    # get unique residues\n",
    "\n",
    "# make a selection token for these residues\n",
    "selection_from_ca_dist_diffmat = []\n",
    "for i in range(len(resids_from_ca_dist_diffmat)):\n",
    "    selection_from_ca_dist_diffmat.append('resid %s' % resids_from_ca_dist_diffmat[i])\n",
    "selection_from_ca_dist_diffmat = ','.join(selection_from_ca_dist_diffmat)\n",
    "selection_from_ca_dist_diffmat = selection_from_ca_dist_diffmat.replace(',', ' or ')\n",
    "\n",
    "# final rmsd_selection for analysis\n",
    "rmsd_selection = '(((' + selection_helices + ') or (' + selection_loops + ')) and (' + selection_from_ca_dist_diffmat + '))' #+ ' and not (resid 116-120 or resid 356-367)'\n",
    "\n",
    "# show the clipped difference matrix\n",
    "#ca_dist_difference_matrix[np.where(abs(ca_dist_difference_matrix) < diffmat_thresh)] = 0\n",
    "#plt.imshow(ca_dist_difference_matrix)\n",
    "#plt.colorbar()\n",
    "\n",
    "# show the selection using nglview\n",
    "rmsd_selection_atoms = u_outward_open.select_atoms(rmsd_selection)\n",
    "view = nv.show_mdanalysis(rmsd_selection_atoms)\n",
    "view.add_licorice(selection=rmsd_selection, color='red')\n",
    "view.center()\n",
    "view\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSDs of all the structures relative to the reference structures\n",
    "\n",
    "# get average positions and make new universe with these positions\n",
    "average_positions = (u_outward_open.atoms.positions + u_inward_open.atoms.positions) / 2\n",
    "u_average = mda.Universe(outward_open_pdb, outward_open_pdb)\n",
    "u_average.atoms.positions = average_positions\n",
    "\n",
    "# define function to get rmsd to a structure\n",
    "def get_rmsd_to_structure(structure):\n",
    "    mobile = mda.Universe(structure_directory + structure, structure_directory + structure) # make universe\n",
    "    mobile.atoms.residues.resids += resid_offset                                            # renumber residues in mobile\n",
    "    rmsds = alignto(mobile, ref, select=rmsd_selection, match_atoms=True, weights=None)     # these ref selections are different becasue ref has different residue numbering\n",
    "    return [structure, rmsds[1]]                                                            # [1] = rmsd after alignment\n",
    "\n",
    "# define a function to calculate the SASA of a structure\n",
    "def get_sasa(structure):\n",
    "    p = PDBParser(QUIET=1)\n",
    "    struct = p.get_structure(structure, structure_directory + structure)\n",
    "    sr = ShrakeRupley(probe_radius=1.4, n_points=100)\n",
    "    sr.compute(struct, level=\"S\")\n",
    "    return [structure, struct.sasa]  \n",
    "\n",
    "rmsd_to_outward = {}\n",
    "\n",
    "# outward open\n",
    "ref = u_outward_open\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    rmsds = list(tqdm(pool.imap(get_rmsd_to_structure, structures), total=len(structures)))\n",
    "rmsd_to_outward = dict(rmsds)   # make this list of tuples into a dictionary\n",
    "\n",
    "rmsd_to_inward = {}\n",
    "\n",
    "# inward open\n",
    "ref = u_inward_open\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    rmsds = list(tqdm(pool.imap(get_rmsd_to_structure, structures), total=len(structures)))\n",
    "rmsd_to_inward = dict(rmsds)   # make this list of tuples into a dictionary\n",
    "\n",
    "rmsd_to_average = {}\n",
    "\n",
    "# average\n",
    "ref = u_average\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    rmsds = list(tqdm(pool.imap(get_rmsd_to_structure, structures), total=len(structures)))\n",
    "rmsd_to_average = dict(rmsds)   # make this list of tuples into a dictionary\n",
    "\n",
    "sasa_dict = {}\n",
    "\n",
    "# solvent accesible surface areas\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    sasas = list(tqdm(pool.imap(get_sasa, structures), total=len(structures)))\n",
    "sasa_dict = dict(sasas)         # make this list of tuples into a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make big pandas dataframe and filter data\n",
    "ensemble_df = pd.DataFrame.from_dict(rmsd_to_outward, orient='index', columns=['rmsd_to_outward'])\n",
    "ensemble_df['rmsd_to_inward'] = rmsd_to_inward.values()\n",
    "ensemble_df['rmsd_to_average'] = rmsd_to_average.values()\n",
    "\n",
    "# take square root of sasa so values are in ansgroms (rather than square angstroms)\n",
    "ensemble_df['sasa'] = sasa_dict.values()\n",
    "ensemble_df['sasa'] = ensemble_df['sasa'].apply(np.sqrt)\n",
    "ensemble_df['sasa_negative'] = ensemble_df['sasa'] * -1\n",
    "\n",
    "# additional quantities\n",
    "ensemble_df['rmsd_sum']    = ensemble_df['rmsd_to_outward'] + ensemble_df['rmsd_to_inward']\n",
    "ensemble_df['rmsd_mean']   = ensemble_df['rmsd_sum'] / 2\n",
    "ensemble_df['rmsd_ratio_outwardness'] = 1 - (ensemble_df['rmsd_to_outward'] / ensemble_df['rmsd_sum'])\n",
    "ensemble_df['rmsd_ratio_inwardness']  = 1 - (ensemble_df['rmsd_to_inward'] / ensemble_df['rmsd_sum'])\n",
    "\n",
    "pLDDT_scores = {}\n",
    "\n",
    "# get pLDDT scores from text file in structures directory called file_details.txt that collabfold outputs\n",
    "with open(structure_directory + 'file_details.txt') as f:\n",
    "    for line in f:                                                                      # lookup pLDDT score for structure in ensemble_df in the file\n",
    "        if line.split()[0] in ensemble_df.index:                                            # match the line that contains the structure name\n",
    "            pLDDT_scores[line.split()[0]] = float(line.split()[1].replace('pLDDT:','')) # sanitize line.split()[1] by removing text\n",
    "\n",
    "# add entries to dictionary for the reference structures with pLDDT scores of 100\n",
    "pLDDT_scores['ref_outward.pdb'] = 100\n",
    "pLDDT_scores['ref_inward.pdb'] = 100\n",
    "ensemble_df['pDDLDT'] = pLDDT_scores.values()\n",
    "\n",
    "# backup\n",
    "df_backup = ensemble_df\n",
    "# reset\n",
    "ensemble_df = df_backup\n",
    "\n",
    "# trim all entries with rmsd_mean > thesh # discard junk\n",
    "ensemble_df = ensemble_df[ensemble_df['rmsd_mean'] < thresh_rmsd]    # discard > thresh_rmsd\n",
    "ensemble_df = ensemble_df[ensemble_df['pDDLDT'] > thresh_pLDDT]      # discard < thresh_pLDDT\n",
    "\n",
    "# get the sasa value for the inward and outward facing reference structures from the dataframe \n",
    "thresh_sasa = max(ensemble_df.loc['ref_outward.pdb']['sasa'], ensemble_df.loc['ref_inward.pdb']['sasa'])*1.01   # occluded state should not be more exposed than the reference structures\n",
    "ensemble_df = ensemble_df[ensemble_df['sasa'] <= thresh_sasa]                                               # discard < thresh_sasa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# principal component analysis on filtered ensemble\n",
    "\n",
    "# write a multistate pdb file for the whole ensemble so MDA will interpret it as a trajectory\n",
    "with mda.Writer(base_directory + 'ensemble.pdb', u.atoms.n_atoms) as W:\n",
    "    for structure in ensemble_df.index:\n",
    "        u = mda.Universe(structure_directory + structure, \n",
    "                         structure_directory + structure)\n",
    "        # renumber for consistency and to match selection token   s     \n",
    "        u.atoms.residues.resids += resid_offset\n",
    "        u.atoms.segments.segids = 'A'\n",
    "        u.atoms.chainIDs = 'A'\n",
    "        W.write(u.select_atoms(selection_for_writeout))\n",
    " \n",
    "# make a universe containing all the structures\n",
    "u = mda.Universe(base_directory + \"ensemble.pdb\")\n",
    "\n",
    "# align the ensemble to the selection token\n",
    "aligner = mda.analysis.align.AlignTraj(u, u, select=rmsd_selection, in_memory=True).run()\n",
    "\n",
    "# perform principal component analysis\n",
    "pc = PCA(u, select=rmsd_selection, align=True, mean=None, n_components=None).run()\n",
    "\n",
    "# project coorindates onto the principal components\n",
    "pc_projection = pc.transform(u.select_atoms(rmsd_selection), n_components=n_pcs)\n",
    "\n",
    "# make a dataframe to store the principal components\n",
    "pca_df = pd.DataFrame(pc_projection, columns=['PC{}'.format(i+1) for i in range(n_pcs)])\n",
    "pca_df['structure index'] = pca_df.index * u.trajectory.dt\n",
    "pca_df['structure'] = ensemble_df.index\n",
    "\n",
    "# print out the PCs\n",
    "display(pca_df)\n",
    "\n",
    "# add principal components to the dataframe - making sure the structures are in the same order\n",
    "pca_df = pca_df.sort_values(by=['structure'])\n",
    "pca_df = pca_df.reset_index(drop=True)\n",
    "ensemble_df['PC1'] = pca_df['PC1'].values\n",
    "ensemble_df['PC2'] = pca_df['PC2'].values\n",
    "ensemble_df['PC3'] = pca_df['PC3'].values\n",
    "\n",
    "# visualisation\n",
    "n_pcs = 3\n",
    "for i in range(n_pcs):\n",
    "    pc_n =    pc.p_components[:, i]\n",
    "    trans_n =   pc_projection[:, i]\n",
    "    projected = np.outer(trans_n, pc_n) + pc.mean.flatten()\n",
    "    coordinates = projected.reshape(len(trans_n), -1, 3)\n",
    "    \n",
    "    proj_n = mda.Merge(u.select_atoms(rmsd_selection))\n",
    "    proj_n.load_new(coordinates)\n",
    "    \n",
    "    # write this to a multistate pdb file\n",
    "    with mda.Writer(base_directory + 'pca{}.pdb'.format(i+1), proj1.atoms.n_atoms) as W:\n",
    "        for ts in proj_n.trajectory:\n",
    "            W.write(proj_n.atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim junk structures and make plots\n",
    "\n",
    "# tabulated results\n",
    "print('Closest to end states:')\n",
    "display(ensemble_df.sort_values(by=['rmsd_to_outward']).head(2)[['rmsd_to_outward', 'pDDLDT', 'sasa']])\n",
    "display(ensemble_df.sort_values(by=['rmsd_to_inward']).head(2)[['rmsd_to_inward', 'pDDLDT', 'sasa']])\n",
    "print('Closest to average:')\n",
    "display(ensemble_df.sort_values(by=['rmsd_to_average']).head(1)[['rmsd_to_average', 'pDDLDT', 'sasa']])\n",
    "print('Lowest 5 SASA:')\n",
    "display(ensemble_df.sort_values(by=['sasa']).head(5)[['rmsd_to_outward', 'rmsd_to_inward', 'pDDLDT', 'sasa']])\n",
    "print('Most different:')\n",
    "display(ensemble_df.sort_values(by=['rmsd_mean']).tail(1)[['rmsd_to_outward', 'rmsd_to_inward', 'pDDLDT', 'sasa']])\n",
    "\n",
    "# write pdb of closest to average\n",
    "mobile = mda.Universe(structure_directory + ensemble_df.sort_values(by=['rmsd_to_average']).head(1).index[0], structure_directory + ensemble_df.sort_values(by=['rmsd_to_average']).head(1).index[0], rmsd_selection=rmsd_selection)\n",
    "mobile.atoms.residues.resids += resid_offset\n",
    "alignto(mobile, u_outward_open, select=rmsd_selection, match_atoms=True)\n",
    "writeout=mobile.select_atoms(selection_for_writeout)\n",
    "writeout.atoms.write(base_directory + 'closest_to_average.pdb')\n",
    "\n",
    "# plot 2D x = ratio_outwardness, y = sasaa, coloured by ratio_inwardness\n",
    "plt.scatter(ensemble_df[plot_variable_1], ensemble_df[plot_variable_2], c=ensemble_df[plot_variable_3], cmap='coolwarm')\n",
    "plt.xlabel(plot_variable_1)\n",
    "plt.ylabel(plot_variable_2)\n",
    "plt.colorbar(label=plot_variable_3)\n",
    "plt.annotate('outward facing', (ensemble_df.loc['ref_outward.pdb'][plot_variable_1], ensemble_df.loc['ref_outward.pdb'][plot_variable_2]))\n",
    "plt.annotate('inward facing', (ensemble_df.loc['ref_inward.pdb'][plot_variable_1], ensemble_df.loc['ref_inward.pdb'][plot_variable_2]))\n",
    "plt.show()\n",
    "\n",
    "# plot histogram of rmsd_to_outward and rmsd_to_inward\n",
    "plt.hist(ensemble_df['rmsd_to_outward'], bins=20, alpha=0.5, label='outward facing')\n",
    "plt.hist(ensemble_df['rmsd_to_inward'], bins=20, alpha=0.5, label='inward facing')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('RMSD')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(0)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 2)\n",
    "plt.show()\n",
    "\n",
    "# plot 2 pane histogram of SASA and pLDDT scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(ensemble_df['sasa'], bins=20, alpha=0.5, label='sasa', color='C3')\n",
    "ax1.set_xlabel('SASA')\n",
    "ax1.set_ylabel('Count')\n",
    "ax2.hist(ensemble_df['pDDLDT'], bins=20, alpha=0.5, label='pDDLDT')\n",
    "ax2.set_xlabel('pDDLDT')\n",
    "fig.set_size_inches(10, 2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel calculation of the pairwise RMSD matrix (for the MC energy function used in the next cell)\n",
    "\n",
    "# Initialize a matrix to store pairwise RMSD values\n",
    "rmsd_matrix = np.zeros((len(ensemble_df), len(ensemble_df)))\n",
    "\n",
    "# function to calculate RMSD values in parallel\n",
    "def calculate_rmsd(i):\n",
    "\n",
    "    rmsd_values = []\n",
    "\n",
    "    # setup universe for i-th structure\n",
    "    mobile = mda.Universe(structure_directory + ensemble_df.index[i], structure_directory + ensemble_df.index[i])\n",
    "    if mobile.atoms.residues.resids[0] == 1: # if first resID == one, then residues are already numbered correctly\n",
    "        mobile.atoms.residues.resids += resid_offset\n",
    "\n",
    "    for j in range(len(ensemble_df)):\n",
    "\n",
    "        # setup universe for j-th structure\n",
    "        ref = mda.Universe(structure_directory + ensemble_df.index[j], structure_directory + ensemble_df.index[j])\n",
    "        if ref.atoms.residues.resids[0] == 1: # if first resID == one, then residues are already numbered correctly\n",
    "            ref.atoms.residues.resids += resid_offset\n",
    "\n",
    "        # Calculate RMSD and store it in the list\n",
    "        rmsd = alignto(mobile, ref, select=rmsd_selection, match_atoms=True)[1]\n",
    "        rmsd_values.append(rmsd)\n",
    "\n",
    "    mobile = None       # Release memory by setting the loaded structures to None\n",
    "    ref = None\n",
    "\n",
    "    return rmsd_values\n",
    "\n",
    "# Perform parallel computation of RMSD values\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    results = list(tqdm(pool.imap(calculate_rmsd, range(len(ensemble_df))), total=len(ensemble_df)))\n",
    "\n",
    "# Update the rmsd_matrix with the results\n",
    "for i, rmsd_values in enumerate(results):\n",
    "    rmsd_matrix[i] = rmsd_values\n",
    "\n",
    "results = None  # Release memory by setting the results to None\n",
    "\n",
    "np.save(base_directory + 'rmsd_matrix.npy', rmsd_matrix)    # save the matrix (to avoid recomputing it in the future)\n",
    "\n",
    "# Display progress information\n",
    "print('Calculation completed for', len(ensemble_df), 'pairs of structures', end='\\r')\n",
    "\n",
    "# plot the matrix\n",
    "plt.imshow(rmsd_matrix, cmap='inferno')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a matrix of pairwise SASA differences\n",
    "sasa_matrix = np.zeros((len(ensemble_df), len(ensemble_df)))\n",
    "n_elements = len(ensemble_df) * len(ensemble_df)\n",
    "\n",
    "# all pairwise sasas (these can just be subtracted from eachother)\n",
    "for i in range(len(ensemble_df)):\n",
    "    for j in range(len(ensemble_df)):\n",
    "        sasa_matrix[i,j] = (ensemble_df['sasa'][i] - ensemble_df['sasa'][j])\n",
    "\n",
    "# shwo the matrix\n",
    "plt.imshow(sasa_matrix, cmap='coolwarm')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign bins for binned mc path finding\n",
    "\n",
    "# drop the reference structures from the dataframe temporarily\n",
    "rmsd_df_tmp = ensemble_df.drop(['ref_outward.pdb', 'ref_inward.pdb']) \n",
    "\n",
    "# assign bins such that there are an equal number of structures in each bin\n",
    "bins = np.zeros(mc_n_bins)\n",
    "for i in range(mc_n_bins):\n",
    "    bins[i] = ensemble_df[collective_variable].quantile((i+1)/mc_n_bins)\n",
    "\n",
    "del rmsd_df_tmp # remove temporary dataframe\n",
    "\n",
    "# add a column to the dataframe with the bin number\n",
    "ensemble_df['bin'] = np.digitize(ensemble_df[collective_variable], bins)\n",
    "\n",
    "# display dataframe grouped by bin and show only rmsd columns\n",
    "display(ensemble_df.groupby('bin').mean()[[collective_variable, plot_variable_1, plot_variable_2]])\n",
    "\n",
    "# print any bins that are empty\n",
    "print('Empty Bins:')\n",
    "for i in range(mc_n_bins):\n",
    "    if i not in ensemble_df['bin'].values:\n",
    "        print(i)\n",
    "    \n",
    "# show bin distribution\n",
    "plt.scatter(ensemble_df[plot_variable_1], ensemble_df[plot_variable_2], c=ensemble_df['bin'], cmap='tab20c')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binned MC path finding in parallel\n",
    "\n",
    "# define a function that runs binned monte carlo path finding\n",
    "def binned_mc_path_finding(mc_run):\n",
    "\n",
    "    starting_structure = ensemble_df.sort_values(by=[collective_variable]).head(1).index.values[0]\n",
    "    temperature = mc_temp\n",
    "    wf_sasa = mc_wf_sasa\n",
    "    n_bins = mc_n_bins\n",
    "\n",
    "    mcpath = []    \n",
    "    mcpath.append(starting_structure)\n",
    "\n",
    "    # while the current structure is not in bin n_bins\n",
    "    current_structure = starting_structure\n",
    "    next_bin = 0\n",
    "    while next_bin != n_bins+1:\n",
    "\n",
    "        # the energy proxy is the sum of the square rmsd between each structure in the path\n",
    "        energy = 0\n",
    "        for i in range(len(mcpath) - 1):\n",
    "            energy += rmsd_matrix[np.where(ensemble_df.index.values == mcpath[i])[0][0], np.where(ensemble_df.index.values == mcpath[i+1])[0][0]]**2\n",
    "            energy += sasa_matrix[np.where(ensemble_df.index.values == mcpath[i])[0][0], np.where(ensemble_df.index.values == mcpath[i+1])[0][0]]*wf_sasa\n",
    "\n",
    "        # propose a move by selecting a random non-self structure from the pool\n",
    "        structure_pool = ensemble_df[ensemble_df['bin'] == next_bin].index.values\n",
    "        proposed_structure = np.random.choice(structure_pool[structure_pool != current_structure])\n",
    "\n",
    "        # proposed path\n",
    "        new_mcpath = mcpath.copy()\n",
    "        new_mcpath.append(proposed_structure)\n",
    "\n",
    "        # calcualte energy of proposed path\n",
    "        new_energy = 0\n",
    "        for i in range(len(new_mcpath) - 1):\n",
    "            new_energy += rmsd_matrix[np.where(ensemble_df.index.values == new_mcpath[i])[0][0], np.where(ensemble_df.index.values == new_mcpath[i+1])[0][0]]**2\n",
    "            new_energy += sasa_matrix[np.where(ensemble_df.index.values == new_mcpath[i])[0][0], np.where(ensemble_df.index.values == new_mcpath[i+1])[0][0]]*wf_sasa\n",
    "\n",
    "        # calculate the difference between the two energies\n",
    "        delta_energy = new_energy - energy\n",
    "\n",
    "        # metropolis criterion\n",
    "        if delta_energy < 0:\n",
    "            current_structure = proposed_structure\n",
    "            mcpath.append(current_structure)\n",
    "            # if the proposed structure is in the next bin, increment next_bin\n",
    "            if ensemble_df.loc[proposed_structure]['bin'] == next_bin:\n",
    "                next_bin += 1\n",
    "        # if higher, accept with probability e^(-difference/temp)\n",
    "        else:\n",
    "            if np.random.rand() < np.exp(-delta_energy / temperature):\n",
    "                current_structure = proposed_structure\n",
    "                mcpath.append(current_structure)\n",
    "                # if the proposed structure is in the next bin, increment next_bin\n",
    "                if ensemble_df.loc[proposed_structure]['bin'] == next_bin:\n",
    "                    next_bin += 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # calculate the energy of the final path\n",
    "    energy = 0\n",
    "    for i in range(len(mcpath) - 1):\n",
    "        energy += rmsd_matrix[np.where(ensemble_df.index.values == mcpath[i])[0][0], np.where(ensemble_df.index.values == mcpath[i+1])[0][0]]**2\n",
    "        energy += sasa_matrix[np.where(ensemble_df.index.values == mcpath[i])[0][0], np.where(ensemble_df.index.values == mcpath[i+1])[0][0]]*wf_sasa\n",
    "\n",
    "    return [energy, mcpath]\n",
    "\n",
    "mc_runs = []\n",
    "\n",
    "# run mc_n_bins runs in parallel\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    mc_runs = list(tqdm(pool.imap(binned_mc_path_finding, range(mc_n_runs)), total=mc_n_runs))\n",
    "\n",
    "# turn this mc_runs list object into a pandas dataframe\n",
    "mc_runs_df = pd.DataFrame(mc_runs, columns=['energy', 'path'])\n",
    "mc_runs_df = mc_runs_df.sort_values(by=['energy'])\n",
    "\n",
    "# write out the best run to a multistate pdb file and append timestamp to filename\n",
    "with mda.Writer(base_directory + 'best_run.pdb', u.atoms.n_atoms) as W:\n",
    "    # get the structures of the lowest energy path\n",
    "    for structure in mc_runs_df.head(1)['path'].values[0]:\n",
    "        # if structure is the reference, dont renumber residues\n",
    "        if structure == 'ref_outward.pdb' or structure == 'ref_inward.pdb':\n",
    "            # use a non-reference structure to make the universe\n",
    "            u = mda.Universe(structure_directory + structure, \n",
    "                             structure_directory + structure) # make universe\n",
    "            u.atoms.residues.resids += resid_offset \n",
    "            u.atoms.segments.segids = 'A'\n",
    "            u.atoms.chainIDs = 'A'\n",
    "            W.write(u.select_atoms(selection_for_writeout))\n",
    "        else:\n",
    "            u = mda.Universe(structure_directory + structure, \n",
    "                             structure_directory + structure) # make universe\n",
    "            u.atoms.residues.resids += resid_offset\n",
    "            W.write(u.select_atoms(selection_for_writeout))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the best path\n",
    "\n",
    "# plot all the structures\n",
    "plt.scatter(ensemble_df[plot_variable_1], ensemble_df[plot_variable_2], c=ensemble_df['bin'], cmap='tab20c', alpha=0.8)\n",
    "\n",
    "# for each structure in best run, plot the rmsd to outward and inward from the ensemble_df dataframe\n",
    "for structure in mc_runs_df.head(1)['path'].values[0]:\n",
    "    plt.scatter(ensemble_df.loc[structure][plot_variable_1], ensemble_df.loc[structure][plot_variable_2], c='black')\n",
    "    #plt.annotate(structure, (ensemble_df.loc[structure][plot_variable_1], ensemble_df.loc[structure][plot_variable_2]))   \n",
    "\n",
    "# draw connecting lines\n",
    "for i in range(len(mc_runs_df.head(1)['path'].values[0]) - 1):\n",
    "    # get the rmsd to outward and inward from ensemble_df\n",
    "    x1 = ensemble_df.loc[mc_runs_df.head(1)['path'].values[0][i]][plot_variable_1]\n",
    "    y1 = ensemble_df.loc[mc_runs_df.head(1)['path'].values[0][i]][plot_variable_2]\n",
    "    x2 = ensemble_df.loc[mc_runs_df.head(1)['path'].values[0][i+1]][plot_variable_1]\n",
    "    y2 = ensemble_df.loc[mc_runs_df.head(1)['path'].values[0][i+1]][plot_variable_2]\n",
    "    plt.plot([x1, x2], [y1, y2], c='black', alpha=0.6, linestyle='dashed')\n",
    "\n",
    "plt.xlabel(plot_variable_1)\n",
    "plt.ylabel(plot_variable_2)\n",
    "plt.show()\n",
    "\n",
    "# plot SASA\n",
    "for structure in mc_runs_df.head(1)['path'].values[0]:\n",
    "    plt.bar(structure, ensemble_df.loc[structure]['sasa'], alpha=0.5, color='C0')\n",
    "plt.ylabel('SASA')\n",
    "plt.ylim(ensemble_df['sasa'].min()-1, ensemble_df['sasa'].max()+1)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "print('Best Run:')\n",
    "mc_runs_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run propka on all the structures\n",
    "from propkatraj import PropkaTraj\n",
    "\n",
    "residues = [305, 346, 205, 332]\n",
    "# copy dataframe \n",
    "pka_df = ensemble_df\n",
    "\n",
    "# make a universe object containing all the structures\n",
    "u = mda.Universe(structure_directory + structures[0], structure_directory + structures[0])\n",
    "\n",
    "# loop thorugh the structures making a universe object for each\n",
    "for structure in structures[1:]:\n",
    "    u = mda.Universe(structure_directory + structure, structure_directory + structure)\n",
    "    # renumber residues\n",
    "    u.atoms.residues.resids += resid_offset\n",
    "\n",
    "    pkatraj = PropkaTraj(u, select='protein', skip_failure=True)\n",
    "    pkatraj.run()   # creates a pandas dataframe with the pka values for each residue in each frame results.pkas\n",
    "    struc_pkas = pkatraj.results.pkas.describe()\n",
    "    \n",
    "    for residue in residues:\n",
    "        # get the mean pka for the residue of interest\n",
    "        pka = struc_pkas.loc['mean', residue]\n",
    "        # add this pka value to a column labelled residue in the pka_df with the structure name as the index \n",
    "        pka_df.loc[structure, 'pka_' + str(residue)] = pka\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
